//memory-bank/askspecify-simplification.md
# askSpecify Tool Simplification - Implementation Complete

## **BEFORE: Over-Engineered Flow**
```
User: "make it 3 seconds"
â†“
Brain LLM: "This is ambiguous, need clarification"
â†“  
Brain LLM: calls askSpecify tool
â†“
askSpecify Tool: calls conversationalResponseService  
â†“
conversationalResponseService: generates question via another LLM call
â†“
askSpecify Tool: returns question
â†“
Brain LLM: sends question to user
```

## **AFTER: Simplified Direct Flow**
```
User: "make it 3 seconds"
â†“
Brain LLM: "This is ambiguous, I'll ask directly"
â†“
Brain LLM: generates clarification question in response
â†“
User sees: "I can help with that! Do you want to:
1. Trim the scene to 3 seconds total, or
2. Speed up the animations to fit in 3 seconds?

Please let me know which option you prefer."
```

## **Changes Made**

### **1. Removed askSpecify Tool (`orchestrator.ts`)**
- âœ… Removed `askSpecifyTool` from imports
- âœ… Removed from tool initialization array
- âœ… Commented out askSpecify handling in `processToolResult`
- âœ… Commented out askSpecify case in `prepareToolInput`

### **2. Updated Brain LLM Prompt**
- âœ… Removed askSpecify from tool selection options
- âœ… Added clarification detection logic
- âœ… Added new JSON response format for clarifications:
  ```json
  {
    "needsClarification": true,
    "clarificationQuestion": "Specific question to ask the user",
    "reasoning": "Why clarification is needed"
  }
  ```

### **3. Added Direct Clarification Handling**
- âœ… Added logic in `processUserInput` to detect `needsClarification` 
- âœ… Return clarification question directly as chat response
- âœ… Keep `isAskSpecify: true` flag for compatibility
- âœ… Added type definitions for clarification response

### **4. Enhanced Follow-up Detection**
- âœ… Existing follow-up detection logic remains unchanged
- âœ… Brain LLM still recognizes when user responds to clarification
- âœ… Proceeds with appropriate tool (editScene, addScene, deleteScene)

## **Benefits Achieved**

1. **ðŸš€ Faster Response**: Eliminated double LLM calls
2. **ðŸ§  More Contextual**: Brain has full conversation context
3. **ðŸŽ¯ Natural Flow**: Direct conversational questions
4. **ðŸ”§ Easier Debug**: Fewer layers to trace
5. **ðŸ’° Cost Effective**: One LLM call instead of two

## **Example Clarification Questions**

**Duration Ambiguity:**
```
"I can help with that! Do you want to:
1. Trim the scene to 3 seconds total, or
2. Speed up the animations to fit in 3 seconds?

Please let me know which option you prefer."
```

**Scene Reference Ambiguity:**
```
"I see you have multiple scenes. Which scene's background would you like me to change?

Scene 1: Product Demo (ID: abc123)
Scene 2: Call to Action (ID: def456)

Please specify which scene you'd like to modify."
```

## **Compatibility Notes**

- âœ… `isAskSpecify: true` flag maintained for frontend compatibility
- âœ… Follow-up detection logic unchanged
- âœ… All existing clarification flows work the same
- âœ… No frontend changes required

## **Status: âœ… COMPLETE**

The askSpecify tool has been successfully removed and replaced with direct Brain LLM clarification handling. The system is now simpler, faster, and more intelligent while maintaining full backward compatibility.
