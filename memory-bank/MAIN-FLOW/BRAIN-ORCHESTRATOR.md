//memory-bank/sprints/sprint31/BRAIN-ORCHESTRATOR.md
# Brain Orchestrator Analysis (`orchestrator.ts`)

This document provides a detailed analysis of the `BrainOrchestrator` class found in `src/server/services/brain/orchestrator.ts`. This orchestrator is a central component responsible for understanding user intent and coordinating the execution of various MCP (Model-Controller-Presenter) tools to fulfill user requests related to video scene manipulation.

## 1. Overview

- **File Location**: `src/server/services/brain/orchestrator.ts`
- **Purpose**: To act as the primary decision-making engine that interprets user prompts, selects the appropriate MCP tool(s) (e.g., `addSceneTool`, `editSceneTool`, `deleteSceneTool`, `askSpecifyTool`), prepares their inputs, executes them, and processes their results. It can handle single tool operations as well as multi-step workflows.
- **Core Mechanism**: Uses an LLM (specifically GPT-4.1-mini) for intent analysis and tool selection. It interacts with a `toolRegistry` to manage and invoke registered MCP tools. It also leverages a `conversationalResponseService` to generate user-facing messages.

## 2. Input Interface (`OrchestrationInput`)

The `BrainOrchestrator.processUserInput` method expects an object with the following structure:

-   `prompt` (string, required): The raw user input or command.
-   `projectId` (string, required): The ID of the project the user is currently working on.
-   `userId` (string, required): The ID of the user making the request.
-   `userContext` (Record<string, unknown>, optional): Additional, potentially structured, context about the user's current state or selections in the UI.
-   `storyboardSoFar` (array of any, optional): An array representing the current state of the storyboard (list of scenes with their properties). This provides crucial context for most operations.
-   `chatHistory` (array of objects, optional): A history of the conversation, where each object has `role` (string) and `content` (string). This helps in understanding nuanced requests.

## 3. Output Interface (`OrchestrationOutput`)

The `processUserInput` method returns a promise that resolves to an object with the following structure:

-   `success` (boolean): Indicates if the overall operation was successful.
-   `result` (any, optional): The primary result from the executed tool or workflow. The structure depends on the tool.
-   `toolUsed` (string, optional): The name of the MCP tool that was executed (or a string like `workflow_X_steps`).
-   `reasoning` (string, optional): The reasoning provided by the intent analysis LLM for selecting the tool/workflow.
-   `error` (string, optional): An error message if the operation failed.
-   `chatResponse` (string, optional): A user-facing message summarizing the outcome or asking for clarification. This is often generated by the executed tool or the `conversationalResponseService`.
-   `isAskSpecify` (boolean, optional): A flag set to true if the `askSpecifyTool` was used, indicating the system is asking for clarification.
-   `debug` (object, optional): Debugging information, which might include:
    *   `prompt` (object): The system and user prompts sent to the intent analysis LLM.
    *   `response` (string): The raw response from the LLM.
    *   `parsed` (any): The parsed version of the LLM response.

## 4. Core Responsibilities & Operational Flow

1.  **Initialization (`constructor`)**:
    *   Registers the core MCP tools (`addSceneTool`, `editSceneTool`, `deleteSceneTool`, `askSpecifyTool`) with the `toolRegistry` if not already registered.

2.  **Processing User Input (`processUserInput`)**:
    *   **Logging**: Logs input details for debugging.
    *   **Intent Analysis (`analyzeIntent`)**: 
        *   Sends the user prompt, chat history, storyboard context, and available tool descriptions to an LLM (GPT-4.1-mini).
        *   The LLM's task is to determine the user's intent, select the most appropriate tool (or a sequence of tools for a workflow), and provide reasoning. It can also identify a `targetSceneId` if applicable.
        *   If intent analysis fails, returns an error.
    *   **Workflow Execution (`executeWorkflow`)**: 
        *   If `analyzeIntent` returns a `workflow` (an array of tool steps), this method is called.
        *   It iterates through each step in the workflow:
            *   Prepares input for the current step using `prepareWorkflowStepInput`, potentially using results from previous steps.
            *   Retrieves the tool from `toolRegistry` and executes it.
            *   Processes the tool's result using `processToolResult`.
            *   Accumulates chat responses.
            *   If any step fails, the entire workflow typically fails.
        *   Returns a consolidated `OrchestrationOutput` for the workflow.
    *   **Single Tool Operation**: 
        *   If not a workflow, retrieves the selected tool from `toolRegistry`.
        *   Prepares the specific input for this tool using `prepareToolInput` (which tailors the general `OrchestrationInput` and `toolSelection` details to what the specific tool expects).
        *   Executes the tool using `tool.run(toolInput)`.
        *   Processes the tool's result using `processToolResult`.

3.  **Preparing Tool Input (`prepareToolInput`, `prepareWorkflowStepInput`)**:
    *   These methods are crucial for translating the general `OrchestrationInput` and the LLM's `toolSelection` (or workflow step details) into the precise input schema expected by each individual MCP tool.
    *   This involves mapping fields, extracting specific scene details if a `targetSceneId` is present, and ensuring all required data for the tool is provided.
    *   For example, for `editSceneTool`, it would extract `existingCode`, `existingName`, `existingDuration` for the `targetSceneId` from `storyboardSoFar`.

4.  **Processing Tool Result (`processToolResult`)**:
    *   Takes the raw output from an MCP tool (`MCPResult`).
    *   Standardizes it into the `OrchestrationOutput` format.
    *   Handles database updates if necessary (e.g., after `addSceneTool` successfully generates a scene, this method (or a subsequent one called by it) would insert the new scene into the `scenes` table).
    *   Sets the `isAskSpecify` flag if the `askSpecifyTool` was used.
    *   Ensures a `chatResponse` is available, potentially generating a default one if the tool didn't provide it.

5.  **Error Handling (`handleError`)**:
    *   Catches exceptions during the orchestration process.
    *   Logs the error.
    *   Generates a user-facing error message using `conversationalResponseService`.
    *   Returns an `OrchestrationOutput` with `success: false` and the error details.

## 5. Tool Interaction

-   **Tool Registry (`toolRegistry`)**: The orchestrator uses a central registry to get instances of tools by their name.
-   **Tool Execution**: Tools are executed via their `run()` method, which is part of the `BaseMCPTool` interface.
-   **Dynamic Input Preparation**: The orchestrator dynamically prepares inputs for each tool based on the tool's requirements and the current context.

## 6. Key Dependencies

-   **`openai`**: For making calls to the GPT model for intent analysis.
-   **MCP Tools**: `addSceneTool`, `editSceneTool`, `deleteSceneTool`, `askSpecifyTool`.
-   **`toolRegistry`**: For managing and accessing MCP tool instances.
-   **`conversationalResponseService`**: For generating user-facing messages, including error messages and confirmations.
-   **`db` (Drizzle ORM) and `scenes` schema**: For database interactions, primarily within `processToolResult` (e.g., saving new scenes, updating scene order after deletion/addition) and potentially when preparing tool inputs (e.g., fetching full scene details).

## 7. Considerations

-   **LLM Reliance**: The accuracy of intent analysis and tool selection is heavily dependent on the LLM's performance and the quality of the system prompt given to it.
-   **Prompt Engineering**: The system prompt for the `analyzeIntent` LLM call is critical. It needs to clearly define the available tools, their purpose, and the expected output format for tool selection/workflow definition.
-   **Complexity of `prepareToolInput`**: This method (and its workflow counterpart) can become complex as it needs to cater to the unique input requirements of every registered tool.
-   **State Management**: The orchestrator relies on `storyboardSoFar` being an accurate representation of the current state. Ensuring this is up-to-date is vital.
-   **Workflow Robustness**: Multi-step workflows add complexity. Error handling within workflows (e.g., deciding whether to stop or attempt recovery) is important.
-   **Cost and Latency**: LLM calls for intent analysis add to the processing time and cost of each user interaction.

This orchestrator forms the intelligent core of the application's backend, enabling complex, multi-turn interactions for video creation and editing.
